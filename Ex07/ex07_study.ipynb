{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텍스트 감정분석의 유용성\n",
    "---\n",
    "### 학습 목표\n",
    "- 텍스트에 담긴 감성을 분석(Sentimental Analysis)하는 방법 학습\n",
    "- 텍스트에 담긴 이용자의 감성이 긍정적인지 혹은 부정적인지를 분류(Classification) 할 수 있는 딥러닝 모델 구현\n",
    "---\n",
    "딥러닝을 이용한 텍스트 감성분석은 어떤 점에서 유용할까?\n",
    "- 텍스트 데이터만이 가지고 있는 정보적 특성과 가치는 어떤 것일까?\n",
    "- 감성분석 등 텍스트 분류 모델이 다른 데이터 분석 업무에 어떤 점에서 도움을 주나?\n",
    "- 텍스트 데이터 분석의 기술적 어려움은?\n",
    "- 텍스트 분류 작업을 하는데 딥러닝이 적용되면 어떤 점에서 유리해질까?\n",
    "\n",
    "인공지능 모델을 입력과 출력이 정해진 함수라고 생각해 봅시다.   \n",
    "예를 들어 MNIST 숫자 분류기 모델이라면 이미지 파일을 읽어 들인 매트릭스가 입력이 되고,   \n",
    "이미지 파일에 쓰여 있는 실제 숫자 값이 출력이 되는 함수가 될 것입니다.  \n",
    "이제 텍스트 문장을 입력으로 받아서 그 의미가 긍정이면 1, 부정이면 0을 출력하는 인공지능 모델을 만든다고 생각해 봅시다.   \n",
    "이 모델을 만들기 위해서는 숫자 분류기를 만들 때는 생각할 필요가 없었던 2가지 문제가 생깁니다.  \n",
    "- 텍스트를 어떻게 숫자 행렬로 표현할 수 있나요?  \n",
    "- 텍스트에는 순서가 중요합니다. 입력 데이터의 순서를 인공지능 모델에 어떻게 반영해야 하나요?  \n",
    "\n",
    "## 텍스트 데이터의 특징\n",
    "인공지능 모델의 입력이 될 수 있는 것은 0과 1의 비트로 표현 가능한 숫자만으로 이루어진 매트릭스일 뿐\n",
    "- 그 자체로는 기호일 뿐 텍스트가 내포하는 의미를 기호가 직접 내포하지 않는다\n",
    "- 단어 사전을 만들고 그 단어의 의미를 나타내는 벡터를 짝지어 보려고 하는 것\n",
    "- 딥러닝을 통해 그 벡터를 만들어 낼 수 있다.  \n",
    "\n",
    "### 텍스트를 숫자로 표현하는 방법\n",
    "- index_to_word 딕셔너리 : 단어를 인덱스로 변환\n",
    "- get_encoded_sentence(sentence, word_to_index) 함수 : 문장을 숫자 리스트로 encoding\n",
    "- get_decoded_sentence(encoded_sentence, index_to_word) 함수 : 숫자 리스트를 문장으로 decoding\n",
    "- get_encoded_sentences(sentences, word_to_index) 함수 : 여러 문장을 encoding\n",
    "- get_decoded_sentences(encoded_sentences, index_to_word) : 여러 문장의 encoded 데이터를 문장 리스트로 decoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처리해야 할 문장 리스트\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "\n",
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. \n",
    "# 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "\n",
    "# 단어 'feel'은 숫자 인덱스 4로 바뀝니다.\n",
    "# print(word_to_index['feel'])  \n",
    "\n",
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수\n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수\n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수\n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding 레이어\n",
    "텍스트가 숫자로 변환되어 인공지능 모델의 입력으로 사용될 수 있게 되었지만, 이것으로 충분하지는 않습니다.  \n",
    "우리가 하려는 것은 단어와 그 단어의 의미를 나타내는 벡터를 짝짓는 것  \n",
    "그래서 단어의 의미를 나타내는 벡터를 훈련 가능한 파라미터로 놓고 이를 딥러닝을 통해 학습해서 최적화\n",
    "**Tensorflow, Pytorch** 등의 딥러닝 프레임워크들은 이러한 의미 벡터 파라미터를 구현한 **Embedding 레이어**를 제공합니다.  \n",
    "\n",
    "**자연어 처리(Natural Language Processing)**분야에서 **임베딩(Embedding)**이란?  \n",
    "- 사람이 쓰는 자연어를 기계가 이해할 수 있는 숫자형태인 vector로 바꾼 결과 혹은 그 일련의 과정 전체\n",
    "- 가장 간단한 형태의 임베딩은 단어의 빈도를 그대로 벡터로 사용하는 것  \n",
    "\n",
    "임베딩을 통해 할수있는 것  \n",
    "- 단어나 문장 사이의 **코사인 유사도**가 가장 높은 단어를 구하는 등의 계산  \n",
    "- 벡터 간 연산으로 단어 사이의 의미/문법적 관계 도출, **전이 학습(transfer learning)**\n",
    "- 임베딩은 다른 딥러닝 모델의 입력값으로 자주 쓰이고, 품질 좋은 임베딩을 쓸수록 모델의 성능이 좋아진다.  \n",
    "\n",
    "#### 텍스트 데이터를 워드 벡터 텐서 형태로 다시 표현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n",
      "tf.Tensor(\n",
      "[[[ 0.01800824  0.00109091 -0.03690145 -0.02782474]\n",
      "  [ 0.03383782  0.03039202 -0.00958464  0.03702618]\n",
      "  [-0.01402246  0.03826613  0.04718358  0.00645492]\n",
      "  [ 0.02545371  0.03254351  0.02317086 -0.00195549]\n",
      "  [ 0.01135433 -0.02648982  0.00486221  0.03569087]]\n",
      "\n",
      " [[ 0.01800824  0.00109091 -0.03690145 -0.02782474]\n",
      "  [ 0.03383782  0.03039202 -0.00958464  0.03702618]\n",
      "  [-0.01964334  0.04169286 -0.01786273 -0.01151594]\n",
      "  [-0.03981721 -0.01488172 -0.04473669 -0.04408164]\n",
      "  [ 0.01135433 -0.02648982  0.00486221  0.03569087]]\n",
      "\n",
      " [[ 0.01800824  0.00109091 -0.03690145 -0.02782474]\n",
      "  [ 0.0076717   0.00954638  0.02973614 -0.00288798]\n",
      "  [ 0.03383782  0.03039202 -0.00958464  0.03702618]\n",
      "  [-0.01402246  0.03826613  0.04718358  0.00645492]\n",
      "  [ 0.02231213 -0.01300167  0.04575387 -0.0294359 ]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "####################\n",
    "# input 문장 벡터\n",
    "####################\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype='object') # Error 발생\n",
    "''' >> raw_inputs의 3개 벡터의 길이는 각각 4, 4, 5입니다.\n",
    "숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용 시 Error 발생\n",
    "\n",
    "Embedding 레이어의 인풋이 되는 문장 벡터는 그 길이가 일정해야 한다.     \n",
    "    Tensorflow - tf.keras.preprocessing.sequence.pad_sequences 함수\n",
    "    - 문장 벡터 뒤에 패딩(<PAD>)을 추가하여 길이를 일정하게 맞춰주는 기능을 제공\n",
    "'''\n",
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)\n",
    "\n",
    "####################\n",
    "# embeding\n",
    "####################\n",
    "vocab_size = len(word_to_index) # 위 예시에서 딕셔너리에 포함된 단어 개수는 10개\n",
    "word_vector_dim = 4     # output_dim : 4차원의 워드 벡터를 가정\n",
    "embedding = tf.keras.layers.Embedding(input_dim = vocab_size, \n",
    "                                    output_dim = word_vector_dim, \n",
    "                                    mask_zero=True)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- output shape=(3,5,4) : 3개의 입력 문장, 입력 문장 최대 길이 5, 워드 벡터 차원 수 4\n",
    "---\n",
    "## RNN(Recurrent Neural Network)\n",
    "**시퀀스(Sequence)** 형태의 데이터를 처리하기에 최적인 모델\n",
    "- 시퀀스 데이터 : 순서에 따라 배열된 데이터(음성신호, 시계열 데이터 등)\n",
    "**내부에 순환 구조** : 이전 단계에서 계산한 정보를 현재 단계의 입력으로 사용 가능\n",
    "- 과거의 정보를 기억하고 현재 입력에 대해 컨텍스트를 이해할 수 있는 장점을 제공\n",
    "\n",
    "RNN은 각 단계에서 입력 데이터와 이전 단계의 **은닉 상태(hidden state)** 를 활용하여 출력을 계산한다.  \n",
    "이전 단계의 은닉 상태는 현재 단계에서의 출력에 영향을 줄 뿐만 아니라, 다음 단계의 입력으로도 사용됩니다.  \n",
    "이러한 반복 과정을 통해 RNN은 시퀀스 데이터의 잠재적인 패턴을 학습하고 예측할 수 있습니다.  \n",
    "\n",
    "RNN은 주로 자연어 처리(Natural Language Processing)와 관련된 작업에 활용됩니다.\n",
    "- 기계 번역, 문장 생성, 감성 분석 등에 RNN을 사용하여 문맥을 파악하고 다음 단계의 출력을 생성할 수 있습니다.   \n",
    "\n",
    "RNN의 변종으로는 **LSTM(Long Short-Term Memory)** 과 **GRU(Gated Recurrent Unit)** 가 있으며,  \n",
    "이들은 **RNN의 기울기 소실 문제(Vanishing Gradient Problem)** 를 완화하기 위해 개발된 구조입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 4)           40        \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 8)                 416       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 대신 1-D CNN\n",
    "우리는 이미지 분류기를 구현하면서 2-D CNN을 이미 사용해 본 바 있습니다.   \n",
    "이미지는 시퀀스 데이터가 아닙니다. 이미지 분류기 모델에는 이미지 전체가 한꺼번에 입력으로 사용됩니다.  \n",
    "\n",
    "**1-D Convolution Neural Network(1-D CNN)** : 텍스트를 처리하기 위해 사용 가능\n",
    "- 문장 전체를 한꺼번에 한 방향으로 길이 7짜리 필터로 스캐닝\n",
    "- 7단어 이내에서 발견되는 특징을 추출하여 문장을 분류\n",
    "- RNN 계열보다 병렬처리가 효율적 >> 학습 속도도 훨씬 빠르게 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 4)           40        \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 16)          464       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, None, 16)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, None, 16)          1808      \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 16)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아주 간단히는 GlobalMaxPooling1D() 레이어 하나만 사용하는 방법\n",
    "- 전체 문장 중에서 단 하나의 가장 중요한 단어만 피처로 추출\n",
    "- 그것으로 문장의 긍정/부정을 평가하는 방식\n",
    "- 의외로 성능이 잘 나올 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 4)           40        \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 4)                0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 40        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 외에도 다양한 시도 가능\n",
    "- 1-D CNN과 RNN 레이어를 섞어 사용\n",
    "- FFN(FeedForward Network) 레이어만으로 구성\n",
    "- 최근 각광받고 있는 Transformer 레이어 사용\n",
    "---\n",
    "## IMDB 영화리뷰 감성분석\n",
    "**IMDb Large Movie Dataset**\n",
    "- 50000개의 영어로 작성된 영화 리뷰 텍스트로 구성\n",
    "- 긍정은 1, 부정은 0의 라벨\n",
    "- 50000개의 리뷰 중 절반인 25000개가 훈련용 데이터, 나머지 25000개를 테스트용 데이터로 사용하도록 지정\n",
    "- 이 데이터셋은 tensorflow Keras 데이터셋 안에 포함되어 있어서 손쉽게 다운로드하여 사용할 수 있습니다.\n",
    "\n",
    "### 데이터 가져오기\n",
    "tf.keras.datasets.imdb - load_data(num_words)  \n",
    "- num_words: 단어 사전에 등재할 단의 개수 >> 지정 개수 만큼의 word_to_index 딕셔너리 생성\n",
    "- encode된 텍스트 데이터를 다운로드\n",
    "- encode시 사용한 딕셔너리 제공 : imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n",
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "imdb = tf.keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(f\"훈련 샘플 개수: {len(x_train)}, 테스트 개수: {len(x_test)}\")\n",
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))\n",
    "\n",
    "# word_to_index\n",
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word_to_index 보정 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n",
      "<BOS>\n",
      "4\n",
      "the\n",
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "# 보정 전 x_train[0] 데이터\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "\n",
    "##################################### 보정 작업\n",
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다.\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다.\n",
    "\n",
    "# 보정 후 x_train[0] 데이터\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "# decode 테스트\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장 최대 길이 maxlen 값 설정을 위한 적절한 값 찾아야 한다 >> 전체 모델 성능에 영향\n",
    "- 전체 데이터셋 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 maxlen 설정값 이내에 포함됩니다. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "padding 방식에 따라 RNN을 이용한 딥러닝 적용 시 성능 차이가 발생\n",
    "- 앞쪽('pre') 가 유리하다 : post padding 보다 10% 이상의 테스트 성능 차이 발생\n",
    "- 문장 뒤쪽('post') : 마지막 입력이 무의미한 padding인 경우 비효율적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "## post padding 데이터\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, None, 16)          160000    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 8)                 800       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN 모델 설계\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련 전 검증셋(validation set) 분리 \n",
    "- 훈련용 데이터 셋 25000건 중 10000건 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 27s 728ms/step - loss: 0.6933 - accuracy: 0.4977 - val_loss: 0.6931 - val_accuracy: 0.5018\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 22s 745ms/step - loss: 0.6931 - accuracy: 0.5052 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 26s 859ms/step - loss: 0.6928 - accuracy: 0.5209 - val_loss: 0.6931 - val_accuracy: 0.5035\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 21s 699ms/step - loss: 0.6924 - accuracy: 0.5072 - val_loss: 0.6929 - val_accuracy: 0.5032\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 21s 679ms/step - loss: 0.6896 - accuracy: 0.5131 - val_loss: 0.6909 - val_accuracy: 0.5033\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 22s 726ms/step - loss: 0.6823 - accuracy: 0.5261 - val_loss: 0.6854 - val_accuracy: 0.5170\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 18s 598ms/step - loss: 0.6728 - accuracy: 0.5495 - val_loss: 0.6932 - val_accuracy: 0.5069\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 17s 581ms/step - loss: 0.6822 - accuracy: 0.5317 - val_loss: 0.6875 - val_accuracy: 0.5123\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 19s 613ms/step - loss: 0.6740 - accuracy: 0.5338 - val_loss: 0.6871 - val_accuracy: 0.5122\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 17s 574ms/step - loss: 0.6708 - accuracy: 0.5390 - val_loss: 0.6939 - val_accuracy: 0.5156\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 17s 581ms/step - loss: 0.6685 - accuracy: 0.5518 - val_loss: 0.6894 - val_accuracy: 0.5176\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 17s 570ms/step - loss: 0.6546 - accuracy: 0.5894 - val_loss: 0.6216 - val_accuracy: 0.6784\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 18s 590ms/step - loss: 0.6083 - accuracy: 0.7289 - val_loss: 0.5928 - val_accuracy: 0.6952\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 22s 737ms/step - loss: 0.5843 - accuracy: 0.7099 - val_loss: 0.5889 - val_accuracy: 0.7225\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 20s 673ms/step - loss: 0.5667 - accuracy: 0.7335 - val_loss: 0.5861 - val_accuracy: 0.7052\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 18s 593ms/step - loss: 0.5772 - accuracy: 0.7057 - val_loss: 0.6010 - val_accuracy: 0.6808\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 19s 624ms/step - loss: 0.5758 - accuracy: 0.7192 - val_loss: 0.5923 - val_accuracy: 0.6925\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 20s 661ms/step - loss: 0.5716 - accuracy: 0.7205 - val_loss: 0.5814 - val_accuracy: 0.7193\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 21s 719ms/step - loss: 0.5973 - accuracy: 0.7383 - val_loss: 0.5718 - val_accuracy: 0.7402\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 19s 642ms/step - loss: 0.5690 - accuracy: 0.7480 - val_loss: 0.5822 - val_accuracy: 0.7355\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터로 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 31s - loss: 0.5923 - accuracy: 0.7250 - 31s/epoch - 40ms/step\n",
      "[0.5923455953598022, 0.7250400185585022]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import os    \n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# acc = history_dict['accuracy']\n",
    "# val_acc = history_dict['val_accuracy']\n",
    "# loss = history_dict['loss']\n",
    "# val_loss = history_dict['val_loss']\n",
    "\n",
    "# epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "# plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# # b는 \"파란 실선\"입니다\n",
    "# plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "# plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "# plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습한 Embeding 파라미터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = './data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파라메터를 읽어 word vector로 활용\n",
    "gensim - Word2VecKeyedVectors\n",
    "- 유사도 확인 가능 : similar_by_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01401771, -0.05854594, -0.00291623, -0.03366603,  0.01186193,\n",
       "       -0.03479581,  0.07233099, -0.02694851,  0.01523762,  0.05468585,\n",
       "        0.07342264,  0.00950327, -0.06672791,  0.06683458,  0.07555837,\n",
       "        0.00774099], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bag', 0.9091659188270569),\n",
       " ('wet', 0.8806669116020203),\n",
       " ('electricity', 0.8776379823684692),\n",
       " ('cruelty', 0.8766930103302002),\n",
       " ('talks', 0.8762642741203308),\n",
       " ('news', 0.8710636496543884),\n",
       " ('coffee', 0.8709262013435364),\n",
       " ('23', 0.8704927563667297),\n",
       " ('pleasantly', 0.8665190935134888),\n",
       " ('seal', 0.8650901317596436)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사도 확인\n",
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구글 Word2Vec 모델 적용\n",
    "gensim - KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_path = './data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907791495323181),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100708842277527),\n",
       " ('hate', 0.6003956198692322),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547305345535278),\n",
       " ('absolutely_adore', 0.5536840558052063),\n",
       " ('adores', 0.5440906882286072)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사도 확인 - 메모리를 다소 많이 소비하는 작업 유의!!\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 임베딩 레이어 Word2Vec로 교체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 580, 300)          3000000   \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 574, 16)           33616     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 114, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 108, 16)           1808      \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 16)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 54s 2s/step - loss: 0.6861 - accuracy: 0.5425 - val_loss: 0.6863 - val_accuracy: 0.5474\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 47s 2s/step - loss: 0.6414 - accuracy: 0.6437 - val_loss: 0.6159 - val_accuracy: 0.6842\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 48s 2s/step - loss: 0.5124 - accuracy: 0.7849 - val_loss: 0.4835 - val_accuracy: 0.7587\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.3649 - accuracy: 0.8499 - val_loss: 0.3447 - val_accuracy: 0.8583\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 70s 2s/step - loss: 0.2534 - accuracy: 0.9091 - val_loss: 0.3149 - val_accuracy: 0.8660\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 75s 3s/step - loss: 0.1914 - accuracy: 0.9335 - val_loss: 0.3021 - val_accuracy: 0.8704\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 74s 2s/step - loss: 0.1420 - accuracy: 0.9571 - val_loss: 0.3095 - val_accuracy: 0.8690\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 66s 2s/step - loss: 0.1173 - accuracy: 0.9643 - val_loss: 0.3124 - val_accuracy: 0.8728\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 43s 1s/step - loss: 0.0848 - accuracy: 0.9793 - val_loss: 0.3169 - val_accuracy: 0.8755\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 40s 1s/step - loss: 0.0605 - accuracy: 0.9895 - val_loss: 0.3359 - val_accuracy: 0.8730\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 40s 1s/step - loss: 0.0422 - accuracy: 0.9949 - val_loss: 0.3400 - val_accuracy: 0.8746\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 43s 1s/step - loss: 0.0305 - accuracy: 0.9977 - val_loss: 0.3563 - val_accuracy: 0.8723\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 41s 1s/step - loss: 0.0231 - accuracy: 0.9986 - val_loss: 0.3730 - val_accuracy: 0.8727\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 40s 1s/step - loss: 0.0182 - accuracy: 0.9990 - val_loss: 0.3910 - val_accuracy: 0.8720\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 40s 1s/step - loss: 0.0148 - accuracy: 0.9991 - val_loss: 0.3961 - val_accuracy: 0.8721\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 40s 1s/step - loss: 0.0126 - accuracy: 0.9992 - val_loss: 0.4093 - val_accuracy: 0.8711\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 42s 1s/step - loss: 0.0108 - accuracy: 0.9992 - val_loss: 0.4218 - val_accuracy: 0.8700\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 39s 1s/step - loss: 0.0096 - accuracy: 0.9992 - val_loss: 0.4386 - val_accuracy: 0.8691\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 40s 1s/step - loss: 0.0079 - accuracy: 0.9993 - val_loss: 0.4430 - val_accuracy: 0.8695\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 41s 1s/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 0.4572 - val_accuracy: 0.8684\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 26s - loss: 0.5035 - accuracy: 0.8629 - 26s/epoch - 33ms/step\n",
      "[0.5035013556480408, 0.8628799915313721]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
